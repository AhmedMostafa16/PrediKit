{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "root = os.path.dirname(os.path.abspath(\".\"))\n",
    "sys.path.append(root)\n",
    "\n",
    "import predikit as pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Load DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def load_show(path_or_buf, extension=None, n=3, label=None, **kwargs):\n",
    "    df = pk.DataFrameParser(\n",
    "        path_or_buf=path_or_buf,\n",
    "        extension=extension,\n",
    "        verbose=True,\n",
    "        **kwargs,\n",
    "    )\n",
    "    if label:\n",
    "        display(f\"From {label}\")\n",
    "\n",
    "    display(f\"Columns: {df.get_column_names()}\")\n",
    "    display(f\"Columns type: {df.get_column_types()}\")\n",
    "    display(f\"Parsed column types: {df.get_column_types(parsed=True)}\")\n",
    "    display(f\"Numeric columns: {df.get_numeric_columns()}\")\n",
    "    display(f\"Non numeric columns: {df.get_non_numeric_columns()}\")\n",
    "    display(df.head(n))\n",
    "\n",
    "\n",
    "# from a Buffered Input Stream\n",
    "f = BytesIO(b\"a,b,c\\n1,2,3\\n4,5,6\\n7,8,9\")\n",
    "load_show(f, extension=\"csv\", label=\"BytesIO\")\n",
    "\n",
    "# from a csv file\n",
    "f = Path(\"./sample_data/airline_bumping.csv\")\n",
    "print(f)\n",
    "load_show(f, n=4, label=\"csv\")\n",
    "\n",
    "# from a pickle file\n",
    "f = Path(\"./sample_data/stations.pickle\")\n",
    "load_show(f, n=5, label=\"pickle\")\n",
    "\n",
    "# from a parquet file\n",
    "f = Path(\"./sample_data/Flights 1m.parquet\")\n",
    "load_show(f, n=3, label=\"parquet\")\n",
    "\n",
    "# from a dictionary\n",
    "data = {\n",
    "    \"Name\": [\"John\", \"Andrea\", \"Rose\", \"Linda\", \"Peter\", \"Meg\"],\n",
    "    \"Age\": [np.nan, 23, 25, 50, np.nan, 50],\n",
    "    \"Credit\": [np.nan, 400, np.nan, 50, 200, np.nan],\n",
    "}\n",
    "load_show(data, n=3, label=\"dict\")\n",
    "\n",
    "# from a list of dictionaries\n",
    "data = [\n",
    "    {\"Name\": \"John\", \"Age\": np.nan, \"Credit\": np.nan},\n",
    "    {\"Name\": \"Andrea\", \"Age\": 23, \"Credit\": 400},\n",
    "    {\"Name\": \"Rose\", \"Age\": 25, \"Credit\": np.nan},\n",
    "    {\"Name\": \"Linda\", \"Age\": 50, \"Credit\": 50},\n",
    "    {\"Name\": \"Peter\", \"Age\": np.nan, \"Credit\": 200},\n",
    "    {\"Name\": \"Meg\", \"Age\": 50, \"Credit\": np.nan},\n",
    "]\n",
    "load_show(data, label=\"list of dicts\")\n",
    "\n",
    "# from a dictionary of Series\n",
    "data = {\n",
    "    \"one\": pd.Series([1.0, 2.0, 3.0], index=[\"a\", \"b\", \"c\"]),\n",
    "    \"two\": pd.Series([1.0, 2.0, 3.0, 4.0], index=[\"a\", \"b\", \"c\", \"d\"]),\n",
    "}\n",
    "load_show(data, label=\"dict of Series\")\n",
    "\n",
    "# from a 2d array\n",
    "data = np.array(\n",
    "    [\n",
    "        [\"John\", \"Andrea\", \"Rose\", \"Linda\", \"Peter\", \"Meg\"],\n",
    "        [np.nan, 23, 35, 50, np.nan, 50],\n",
    "        [np.nan, 400, np.nan, 50, 200, np.nan],\n",
    "    ]\n",
    ")\n",
    "\n",
    "data = data.T\n",
    "load_show(data, label=\"2d array\", columns=[\"Name\", \"Age\", \"Credit\"])\n",
    "\n",
    "\n",
    "# ToDo => add tests for JSON and EXCEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from result import Result\n",
    "\n",
    "\n",
    "def unwrap_value_or_error(result: Result):\n",
    "    if result.is_ok():\n",
    "        return result.unwrap()\n",
    "    return result.unwrap_err()\n",
    "\n",
    "\n",
    "def init_df_sample(sample_number: int = 1):\n",
    "    if sample_number < 0 or sample_number > 5:\n",
    "        raise ValueError(\"sample_number must be between 0 and 4\")\n",
    "\n",
    "    data = {\n",
    "        \"Name\": [\"John\", \"Meg\", \"Rose\", np.nan, \"Peter\", \"Meg\"],\n",
    "        \"Age\": [np.nan, 10, 25, 50, 20, 50],\n",
    "        \"Credit\": [np.nan, 400, np.nan, 200_00_00, 1_000_000, np.nan],\n",
    "    }\n",
    "    samples = {\n",
    "        1: data,\n",
    "        2: \"./sample_data/airline_bumping.csv\",\n",
    "        3: \"./sample_data/stations.pickle\",\n",
    "        4: \"./sample_data/Flights 1m.csv\",\n",
    "        5: \"./sample_data/Flights 1m.parquet\",\n",
    "    }\n",
    "\n",
    "    return pk.DataFrameParser(path_or_buf=samples[sample_number])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = init_df_sample(1)\n",
    "display(df)\n",
    "\n",
    "# bug in MODE doesn't fill all NaNs\n",
    "mvp = pk.MissingValuesProcessor(strategy=pk.MissingValueStrategy.MODE)\n",
    "result = mvp.fit_transform(df)\n",
    "\n",
    "if result.is_err():\n",
    "    raise ValueError(\n",
    "        \"Operation must be done for later operation (Outliers Detection)\"\n",
    "    )\n",
    "\n",
    "df = result.unwrap()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = init_df_sample(2)\n",
    "display(df)\n",
    "op = pk.OutliersProcessor(\n",
    "    \"z_score\",\n",
    "    # threshold=3,\n",
    "    verbose=True,\n",
    "    add_indicator=True,\n",
    ")\n",
    "result = op.fit_transform(df, columns=[\"total_passengers\"])\n",
    "\n",
    "unwrap_value_or_error(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = init_df_sample(2)\n",
    "col: str = \"year\"\n",
    "# display(df)\n",
    "bf = pk.BasicFilteringProcessor(\n",
    "    \"!=\",\n",
    "    value=\"2015\",\n",
    "    case_sensitive=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# bf\n",
    "display(df)\n",
    "result = bf.fit_transform(df, column=col)\n",
    "\n",
    "unwrap_value_or_error(result)\n",
    "# result_unpacked = result.unwrap()\n",
    "# print(result_unpacked)\n",
    "# bf\n",
    "# display(df)\n",
    "\n",
    "\n",
    "# bf.set_params(operator=pk.FilterOperator.EQUAL, value=50)\n",
    "# display(bf.fit_transform(df, column=\"Age\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Modifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\n",
    "#     \"Name\": [\n",
    "#         \"   John   .!,@  \",\n",
    "#         \"#A nd@rea$\",\n",
    "#         \"Rose\",\n",
    "#         \"L0ind9a\",\n",
    "#         \"P!e1t@e_r\",\n",
    "#         \"M+e - g$\",\n",
    "#     ],\n",
    "#     \"Age\": [np.nan, 200, 25, 50, np.nan, 50],\n",
    "#     \"Credit\": [np.nan, 400, np.nan, 200_00_00, 1_000_000, np.nan],\n",
    "# }\n",
    "# df = pk.DataFrameParser(data)\n",
    "\n",
    "\n",
    "df = init_df_sample(2)\n",
    "\n",
    "sop = pk.StringOperationsProcessor(\n",
    "    \"title\",\n",
    "    trim=True,\n",
    "    remove_letters=False,\n",
    "    remove_whitespace=True,\n",
    "    remove_numbers=True,\n",
    "    remove_punctuation=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "\n",
    "display(df.head(3))\n",
    "# result = sop.fit_transform(df, columns=[\"year\"])\n",
    "unwrap_value_or_error(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleanse as a Whole\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = {\n",
    "#     \"Name\": [\n",
    "#         \"   John   .!,@  \",\n",
    "#         \"#A nd@rea$\",\n",
    "#         \"Rose\",\n",
    "#         \"L0ind9a\",\n",
    "#         \"P!e1t@e_r\",\n",
    "#         \"M+e - g$\",\n",
    "#     ],\n",
    "#     \"Age\": [np.nan, 200, 25, 50, np.nan, 50],\n",
    "#     \"Credit\": [np.nan, 400, np.nan, 200_00_00, 1_000_000, np.nan],\n",
    "# }\n",
    "\n",
    "df = init_df_sample(2)\n",
    "\n",
    "# dc = pk.DataCleanser(\n",
    "#     missing_clean=True,\n",
    "#     missing_strategy=\"median\",\n",
    "#     missing_indicator=True,\n",
    "#     missing_fill_value=0,\n",
    "#     outlier_clean=True,\n",
    "#     outlier_method=\"z\",\n",
    "#     outlier_threshold=1.5,\n",
    "#     outlier_indicator=True,\n",
    "#     str_trim=True,\n",
    "#     str_remove_whitespace=True,\n",
    "#     str_remove_letters=True,\n",
    "#     str_remove_numbers=True,\n",
    "#     str_remove_punctuation=True,\n",
    "#     verbose=False,\n",
    "# )\n",
    "# props = {\n",
    "#     \"removeOutliers\": True,\n",
    "#     \"outlierMethod\": \"z_score\",\n",
    "#     \"replaceNulls\": False,\n",
    "#     \"replaceNullWith\": \"mean\",\n",
    "#     \"fillValue\": \"\",\n",
    "#     \"modifyCase\": \"lower\",\n",
    "#     \"removeWhitespace\": True,\n",
    "#     \"removePunctuation\": False,\n",
    "#     \"removeNumbers\": True,\n",
    "#     \"removeLetters\": False,\n",
    "#     \"trim\": False,\n",
    "#     \"selectedColumns\": [],\n",
    "# }\n",
    "\n",
    "\n",
    "props = {\n",
    "    \"missingClean\": False,\n",
    "    \"missingStrategy\": \"median\",\n",
    "    \"missingFillValue\": \"\",\n",
    "    \"missingIndicator\": False,\n",
    "    \"outlierClean\": False,\n",
    "    \"outlierMethod\": \"z_score\",\n",
    "    \"outlierThreshold\": 3,\n",
    "    \"outlierIndicator\": False,\n",
    "    \"strOperations\": True,\n",
    "    \"strCaseModifierMethod\": \"lower\",\n",
    "    \"strTrim\": False,\n",
    "    \"strRemoveWhitespace\": False,\n",
    "    \"strRemoveNumbers\": False,\n",
    "    \"strRemoveLetters\": False,\n",
    "    \"strRemovePunctuation\": False,\n",
    "    \"selectedColumns\": [],\n",
    "}\n",
    "\n",
    "dc = pk.DataCleanser(  # TODO: add more options\n",
    "    missing_clean=props[\"missingClean\"],\n",
    "    missing_strategy=props[\"missingStrategy\"],\n",
    "    missing_fill_value=props[\"missingFillValue\"],\n",
    "    missing_indicator=props[\"missingIndicator\"],\n",
    "    outlier_clean=props[\"outlierClean\"],\n",
    "    outlier_method=props[\"outlierMethod\"],\n",
    "    outlier_indicator=props[\"outlierIndicator\"],\n",
    "    str_operations=props[\"strOperations\"],\n",
    "    str_remove_letters=props[\"strRemoveLetters\"],\n",
    "    str_remove_numbers=props[\"strRemoveNumbers\"],\n",
    "    str_remove_punctuation=props[\"strRemovePunctuation\"],\n",
    "    str_remove_whitespace=props[\"strRemoveWhitespace\"],\n",
    "    str_case_modifier_method=props[\"strCaseModifierMethod\"],\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "result = dc.fit_transform(df)\n",
    "# result\n",
    "unwrap_value_or_error(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = init_df_sample(1)\n",
    "enc = pk.EncodingProcessor(\n",
    "    pk.EncodingStrategies.OneHotEncoder,\n",
    "    verbose=True,\n",
    "    sparse_output=True,\n",
    ")\n",
    "cols = [\"Name\"]\n",
    "result = enc.fit_transform(df, columns=cols)\n",
    "unwrap_value_or_error(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "print(f\"Running on {platform.system()}\")\n",
    "\n",
    "# cross platform\n",
    "dfe = pk.DataFrameExporter(df, extension=pk.FileExtension.CSV)\n",
    "dfe.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predikit.preprocessing import FeatureSelection\n",
    "\n",
    "data = {\n",
    "    \"Name\": [\"John\", \"Andrea\", \"Rose\", \"Linda\", \"Peter\", \"Meg\"],\n",
    "    \"Age\": [21, 23, 25, 50, 48, 50],\n",
    "    \"Credit\": [74512, 400, 56132, 50, 1_000_000, 45121],\n",
    "}\n",
    "\n",
    "df = pk.DataFrameParser(data)\n",
    "fs = FeatureSelection(exclude_dtypes=[\"object\"], verbose=True)\n",
    "# new_df = fs.fit_transform(df, columns=[\"Age\"], dtypes=[\"object\"])\n",
    "# new_df = fs.fit_transform(df)\n",
    "# new_df = fs.fit_transform(df, dtypes=[\"object\"])\n",
    "# new_df = fs.fit_transform(df, columns=[\"Age\"])\n",
    "# new_df = fs.fit_transform(df, columns=[\"Name\"], dtypes=[\"number\"])\n",
    "result = fs.fit_transform(df, columns=[\"Credit\", \"Age\"])\n",
    "unwrap_value_or_error(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\n",
    "    \"./sample_data/merged_quotation_data.xlsx\",\n",
    "    header=0,\n",
    "    index_col=None,\n",
    "    nrows=10,\n",
    ")\n",
    "\n",
    "\n",
    "# df.query(\"`priority level`.str.contains('high', case=False)\")\n",
    "cmp_ziegler = df[(df[\"Company\"] == \"ZIEGLER FRANCE SA\")]\n",
    "cmp_bollore = df[(df[\"Company\"] == \"BOLLORE LOGISTICS\")]\n",
    "print(cmp_ziegler.index)\n",
    "print(cmp_bollore.index)\n",
    "\n",
    "print(len(cmp_ziegler.index))\n",
    "print(len(cmp_bollore.index))\n",
    "df\n",
    "# target = \"DN NUMBER\"\n",
    "# res = df[cmp_ziegler[target] == cmp_bollore[target]]\n",
    "# res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
